One-Hot Encoding of Categorical Data for Machine Learning
Overview
This project involves preprocessing a car dataset to prepare it for machine learning models. Specifically, it demonstrates how to apply One-Hot Encoding using scikit-learn to convert categorical data into numerical form, making it suitable for model training.

Dataset
The dataset contains information about cars, including:

fuel: Type of fuel used (e.g., Petrol, Diesel).
owner: Type of ownership (e.g., First owner, Second owner).
brand: Brand of the car.
km_driven: Number of kilometers driven by the car.

Key Steps:
Data Loading: The dataset is loaded using pandas and split into training and testing sets using train_test_split from scikit-learn.

One-Hot Encoding:
OneHotEncoder is used to convert categorical columns (fuel and owner) into binary columns.
This ensures that the machine learning model treats categories as separate features without assuming any ordinal relationships.
The drop='first' option is used to avoid the dummy variable trap, reducing redundancy in features.
Combining Features: The one-hot encoded features are combined with numerical features (e.g., km_driven) using np.hstack() for model training.
Handling Rare Categories: Brands that appear less than a certain threshold are grouped into an "uncommon" category to reduce the number of columns generated during encoding.

Benefits of One-Hot Encoding:
Converts categorical data into a numerical format, allowing models to process it.
Avoids the assumption of ordinal relationships between categories.
Improves the performance of distance-based algorithms and linear models.

Usage
Load the dataset and preprocess the categorical data using OneHotEncoder.
Use fit_transform() for the training set and transform() for the test set to ensure consistent encoding.
Combine the transformed features with other numerical data for model training.
Handle infrequent categories by replacing them with a common category like "uncommon."
